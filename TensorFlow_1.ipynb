{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Flow\n",
    "1. Assemble a graph\n",
    "2. Use a session to execute the Graph\n",
    "\n",
    "Tensor - n Dimensional array\n",
    "\n",
    "Basic Operations - ADD  \n",
    "a = tf.add(3,5)\n",
    "\n",
    "A computation graph is created where-: \n",
    "1. Nodes - Operators,Variables and Constants\n",
    "2. Edges - Tensors\n",
    "\n",
    "Tensor -> data\n",
    "TensorFlow = Tensor + Flow = Data + Flow  \n",
    "Mind = Blown! :P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output because 'a' is currently a node in the graph generated by TensorFlow. Value of a can only be obtained after the graph is executed!\n",
    "\n",
    "## Steps - :\n",
    "1. Assemble a graph.\n",
    "2. Create a Session and assign it to a variable, sess (to call it later).\n",
    "3. Within session, evaluate graphs to do the necessary computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3,5)\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(3,5)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Session()\n",
    "A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated.  \n",
    "\n",
    "Session will aso allocate memory to store the current values of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More Graphs\n",
    "x = 2 \n",
    "y = 3\n",
    "op1 = tf.add(x,y)\n",
    "op2 = tf.multiply(x,y)\n",
    "op3 = tf.pow(op2,op1)\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x,y)\n",
    "mul_op = tf.multiply(x,y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op,mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, value of 'useless' will not be computed as we dont require it for the computation of 'pow_op'\n",
    "\n",
    "-> General Syntax - tf.Session(fetches, feed_dict = None, options = None, run_metadata = None)  \n",
    "fetches - list of tensors whoes values you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x,y)\n",
    "mul_op = tf.multiply(x,y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op,mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run([pow_op, useless])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is possible to break graphs into several chunks and run them across multiple CPUs, GPUs, TPUs or other devices\n",
    "\n",
    "Example - AlexNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get available devices on which you can perform computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_cpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'CPU']\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_cpus() + get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Computation\n",
    "To put a graph on a specific CPU or GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Graph\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0], name ='a')\n",
    "    b = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0], name ='b')\n",
    "    c = tf.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Session with og_device_placement set to True\n",
    "sess = tf.Session(config = tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  4.  9. 16. 25. 36.]\n"
     ]
    }
   ],
   "source": [
    "#Run the Operation\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buiding more than one graph\n",
    "Generally you dont need more than one graph as Session only runs the default graph.\n",
    "\n",
    "1. Multiple graphs require mutiple session, each will try to use al available resources by default\n",
    "2. Can't pass data betweeen them without passing them through python/numpy, which doesn't  work in distributed network\n",
    "3. Its better to have disconnect graphs within one graph\n",
    "\n",
    "But if you really want to make mutiple graphs then follow :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a graph\n",
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    q = tf.add(3,5)\n",
    "sess = tf.Session(graph = g)\n",
    "sess.run(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To handle the default graph\n",
    "w = tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note : Dont mix dfault graphs and user created graphs\n",
    "g = tf.Graph()\n",
    "\n",
    "#Add ops to the default graph\n",
    "a = tf.constant(3)\n",
    "\n",
    "#Add ops to the user created graph\n",
    "with g.as_default():\n",
    "    b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "# Add operations to the default graph\n",
    "with g1.as_default():\n",
    "    a = tf.constant(3)\n",
    "\n",
    "# Add operations to the user created graphs\n",
    "with g2.as_default():\n",
    "    b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing of two graphs is highly prone to erroors as you can mess up Tensors and Operations of different Graphs.\n",
    "\n",
    "Hence, Practice of using different graphs is avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Graphs?\n",
    "While working with TensorFlow, a question might arise that, Why Graphs?  \n",
    "1. Save Computations - Only run subgraphs which leads to values you want to fetch\n",
    "2. Break coputation into small, differential pieces to faciitace auto-differentiation\n",
    "3. Facilitate distributed computations\n",
    "4. Many algorithms are visualized and taught as directed graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
