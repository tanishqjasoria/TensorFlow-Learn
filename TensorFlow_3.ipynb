{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.constant() and tf.Variable()\n",
    "1. Contant values are stored in graph definition\n",
    "2. Session allocate memory to store variable values\n",
    "\n",
    "### tf.placeholder and feed_dict\n",
    "1. Feed values into placeholder with a dictionary(feed_dict)\n",
    "2. Easy to use but poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Inference : Y_predicted = w * X + b  \n",
    "MSE : (y-y_predicted)^2  \n",
    "Data : birth_life_2010.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1661.863764550287\n",
      "Epoch 1: 956.3224439573916\n",
      "Epoch 2: 844.6737683409139\n",
      "Epoch 3: 750.7312372197838\n",
      "Epoch 4: 667.659830722252\n",
      "Epoch 5: 594.1417484349327\n",
      "Epoch 6: 529.0787271179651\n",
      "Epoch 7: 471.5003584364135\n",
      "Epoch 8: 420.5458252520938\n",
      "Epoch 9: 375.45531067297253\n",
      "Epoch 10: 335.55436177954664\n",
      "Epoch 11: 300.24627770512666\n",
      "Epoch 12: 269.00374521501146\n",
      "Epoch 13: 241.3595776562824\n",
      "Epoch 14: 216.9003910217238\n",
      "Epoch 15: 195.25972397061292\n",
      "Epoch 16: 176.1137731664483\n",
      "Epoch 17: 159.17551683403158\n",
      "Epoch 18: 144.19069889799545\n",
      "Epoch 19: 130.93503690609023\n",
      "Epoch 20: 119.20935661137888\n",
      "Epoch 21: 108.83793506244884\n",
      "Epoch 22: 99.66458668207358\n",
      "Epoch 23: 91.55171666162971\n",
      "Epoch 24: 84.37658985632197\n",
      "Epoch 25: 78.03213362396008\n",
      "Epoch 26: 72.42178616552172\n",
      "Epoch 27: 67.46132107331957\n",
      "Epoch 28: 63.07563027821873\n",
      "Epoch 29: 59.19871881428714\n",
      "Epoch 30: 55.77163058824279\n",
      "Epoch 31: 52.742706123048954\n",
      "Epoch 32: 50.06563247971506\n",
      "Epoch 33: 47.70006537150391\n",
      "Epoch 34: 45.61017402416389\n",
      "Epoch 35: 43.763794843404014\n",
      "Epoch 36: 42.13259061904698\n",
      "Epoch 37: 40.692217106133775\n",
      "Epoch 38: 39.420219863367905\n",
      "Epoch 39: 38.297008645340895\n",
      "Epoch 40: 37.305592010505066\n",
      "Epoch 41: 36.43066341609841\n",
      "Epoch 42: 35.658454647898296\n",
      "Epoch 43: 34.977248985403655\n",
      "Epoch 44: 34.376551568753236\n",
      "Epoch 45: 33.846705867195695\n",
      "Epoch 46: 33.37967463995998\n",
      "Epoch 47: 32.9680108638946\n",
      "Epoch 48: 32.60548541990942\n",
      "Epoch 49: 32.28618434173986\n",
      "Epoch 50: 32.004961317298495\n",
      "Epoch 51: 31.75752976890163\n",
      "Epoch 52: 31.53978877073019\n",
      "Epoch 53: 31.34836144135732\n",
      "Epoch 54: 31.180118720635072\n",
      "Epoch 55: 31.03225782010038\n",
      "Epoch 56: 30.902463045723714\n",
      "Epoch 57: 30.788599823501748\n",
      "Epoch 58: 30.68872023182676\n",
      "Epoch 59: 30.60122912194102\n",
      "Epoch 60: 30.524589418089263\n",
      "Epoch 61: 30.457532704476954\n",
      "Epoch 62: 30.398964531451316\n",
      "Epoch 63: 30.34777825418737\n",
      "Epoch 64: 30.303121465726413\n",
      "Epoch 65: 30.264247165074092\n",
      "Epoch 66: 30.230395186190357\n",
      "Epoch 67: 30.200965440111528\n",
      "Epoch 68: 30.175501555469697\n",
      "Epoch 69: 30.153343991707324\n",
      "Epoch 70: 30.134226098457216\n",
      "Epoch 71: 30.117758308603477\n",
      "Epoch 72: 30.103543774372174\n",
      "Epoch 73: 30.091394110470336\n",
      "Epoch 74: 30.08093890536509\n",
      "Epoch 75: 30.072084357345624\n",
      "Epoch 76: 30.06452434975899\n",
      "Epoch 77: 30.0581486002297\n",
      "Epoch 78: 30.05278219980139\n",
      "Epoch 79: 30.04828310612785\n",
      "Epoch 80: 30.04458791257593\n",
      "Epoch 81: 30.041549566215345\n",
      "Epoch 82: 30.039046151249817\n",
      "Epoch 83: 30.037039793959796\n",
      "Epoch 84: 30.035464155240486\n",
      "Epoch 85: 30.034287342776263\n",
      "Epoch 86: 30.033386764163456\n",
      "Epoch 87: 30.03276857610855\n",
      "Epoch 88: 30.032388654677273\n",
      "Epoch 89: 30.032152204158926\n",
      "Epoch 90: 30.03209388247043\n",
      "Epoch 91: 30.03219517776896\n",
      "Epoch 92: 30.032402951199575\n",
      "Epoch 93: 30.03264380555698\n",
      "Epoch 94: 30.033044778692265\n",
      "Epoch 95: 30.03343712379727\n",
      "Epoch 96: 30.033913317535955\n",
      "Epoch 97: 30.03442924663878\n",
      "Epoch 98: 30.0349335548615\n",
      "Epoch 99: 30.03552558278714\n",
      "Took: 5.771556 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "\n",
    "DATA_FILE = 'birth_life_2010.txt'\n",
    "\n",
    "#Read in data from the .txt file\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "\n",
    "X = tf.placeholder(tf.float32, name = 'X')\n",
    "Y = tf.placeholder(tf.float32, name = 'Y')\n",
    "\n",
    "w = tf.get_variable('weights', initializer=tf.constant(0.0))\n",
    "b = tf.get_variable('bias', initializer=tf.constant(0.0))\n",
    "\n",
    "Y_predicted = w*X+b\n",
    "\n",
    "loss = tf.square(Y_predicted - Y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            _, loss_ = sess.run([optimizer,loss], feed_dict={X: x, Y:y})\n",
    "            total_loss += loss_\n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "    \n",
    "    writer.close()\n",
    "    w_out, b_out = sess.run([w, b])\n",
    "\n",
    "print('Took: %f seconds' %(time.time() - start))\n",
    "\n",
    "# uncomment the following lines to see the plot \n",
    "plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n",
    "plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hubber Loss\n",
    "If the difference between the predicted value and the real value is small, square it.  \n",
    "If its large, take its absoute value.\n",
    "<pre>\n",
    "L(y,f(x)) = {(1/2)*(y-f(x))^2       for |y-f(x)| less than equal to d,\n",
    "            {d|y-f(x)| - 0.5d^2     otherwise\n",
    "</pre>\n",
    "\n",
    "tf.cond(pred, fn1, fn2, name=None) -> for conditional statements in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubber_loss(lables,predictions, delta=0.4):\n",
    "    residual = tf.abs(lables-prediction)\n",
    "    def f1(): return 0.5 * tf.square(residual)\n",
    "    def f2(): return delta * residual - 0.5* tf.square(delta)\n",
    "    return tf.cond(residual < delta, f1, f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Control Flow \n",
    "Since TF builds graphs before computations, we have to specify all possible subgraphs beforehand.  \n",
    "PyTorch's dynamic graphs and TF eager excecution help overcome this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data\n",
    "## Placeholder\n",
    "\n",
    "Pro : put data processing outside TF, making it easy to do in Python.  \n",
    "Cons : users often end up processing their data in a single thread and creating data bottleneck that slows execution down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insted use : tf.data.Dataset or tf.data.Iterator  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers (Training Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "_, l = sess.run([optimizer, loss], feed_dict= {X:x, Y:y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session looks at all trainable variables that loss depends on and update them automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Here we will be working on the MNIST Database.   \n",
    "MNIST Dataset - Collection of images of handwriten digits. Each image is a 28x28 array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X : Image of handwritten digit  \n",
    "Y : The digit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-bd8afd291cca>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('data/mnist', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist/train-images-idx3-ubyte.gz already exists\n",
      "data/mnist/train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist/t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist/t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mnist/train-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-29d2b788a222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmnist_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/mnist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TensorFlow-Learn/utils.py\u001b[0m in \u001b[0;36mread_mnist\u001b[0;34m(path, flatten, num_train)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TensorFlow-Learn/utils.py\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(path, dataset, flatten)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-labels-idx1-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">II\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#int8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/mnist/train-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "mnist_folder = 'data/mnist'\n",
    "utils.download_mnist(mnist_folder)\n",
    "train, val, test = utils.read_mnist(mnist_folder, flatten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
